# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KddEuIMHptyRNJV28EyskqaaErqaLfzu

#import library
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report
import tensorflow as tf
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam

"""#Load Dataset"""
#Load Dataset
dataset = pd.read_csv('dataset/income.csv')


"""#Melakukan Exploration Data Analyst"""

print(dataset.head())

print(dataset.info())

sns.countplot(x='income_>50K', data=dataset)
plt.show()

"""#Lakukan Pre-processing dan Data Augmentation yang menurut kamu memberikan dataset yang lebih efisien"""

# Encode fitur kategorikal
label_encoders = {}
kolom_kategorikal = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']

for kolom in kolom_kategorikal:
    le = LabelEncoder()
    dataset[kolom] = le.fit_transform(dataset[kolom])
    label_encoders[kolom] = le

# Split Data
X = dataset.drop('income_>50K', axis=1)
y = dataset['income_>50K']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardisasi
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

#Data Augmentasi

from sklearn.utils import shuffle

# Buat salinan dataset untuk augmentasi
augmented_dataset = dataset.copy()

# Lakukan pengacakan baris pada dataset
augmented_dataset = shuffle(augmented_dataset)

# Duplikat sebagian dataset untuk menambah variasi
augmented_dataset = pd.concat([augmented_dataset, augmented_dataset], ignore_index=True)

# Split Data pada dataset yang telah di-augmentasi
X_augmented = augmented_dataset.drop('income_>50K', axis=1)
y_augmented = augmented_dataset['income_>50K']
X_train_augmented, X_test_augmented, y_train_augmented, y_test_augmented = train_test_split(X_augmented, y_augmented, test_size=0.2, random_state=42)

# Standardisasi pada dataset yang telah di-augmentasi
X_train_augmented = scaler.transform(X_train_augmented)
X_test_augmented = scaler.transform(X_test_augmented)

"""#Implementasikan transfer learning dengan menggunakan model TabNet atau lainnya"""


# Contoh Model DNN yang telah dilatih sebelumnya
pretrained_model = Sequential([
    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
    Dropout(0.5),
    Dense(64, activation='relu'),
    Dropout(0.3),
    Dense(1, activation='sigmoid')
])

# Compile model
pretrained_model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])

# Fit model pada data yang telah di-augmentasi
pretrained_model.fit(X_train_augmented, y_train_augmented, epochs=5, batch_size=32, validation_split=0.2)



# Compile model setelah transfer learning
pretrained_model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])

# Lanjutkan pelatihan setelah transfer learning
pretrained_model.fit(X_train_augmented, y_train_augmented, epochs=10, batch_size=32, validation_data=(X_test_augmented, y_test_augmented))

"""#Lakukan Fit Model dengan epoch yang anda tentukan"""

# Fit Model dengan Epoch yang Ditentukan
epochs = 20

history = pretrained_model.fit(X_train_augmented, y_train_augmented, epochs=epochs, batch_size=32, validation_data=(X_test_augmented, y_test_augmented))

"""#Evaluate Model dengan menampilkan Plot, Loss, Accuracy serta Classification Report"""

# Plot loss dan akurasi
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend(['Train', 'Validation'], loc='upper right')
plt.show()

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(['Train', 'Validation'], loc='lower right')
plt.show()

# Classification Report
from sklearn.metrics import classification_report

y_pred = pretrained_model.predict(X_test_augmented)
y_pred_class = (y_pred > 0.5).astype(int)

print(classification_report(y_test_augmented, y_pred_class))

"""#Lakukan predict pada data test hasil splitting kemudian lakukan perbandingan antara true label dan predict labelnya"""

# Lakukan Predict pada Data Test
y_pred = pretrained_model.predict(X_test_augmented)
y_pred_class = (y_pred > 0.5).astype(int)

# Perbandingan antara True Label dan Predict Label
comparison_df = pd.DataFrame({'True Label': y_test_augmented, 'Predicted Label': y_pred_class.flatten()})
print(comparison_df)

"""#Demonstrasikan hasil tersebut kepada esisten"""

